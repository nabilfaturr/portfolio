import { project_metadata_collection } from "@/lib/project-metadata";
import SectionProvider from "@/components/shared/provider/section-provider";
import VideoDemo from "../../../components/shared/mdx/video-demo";
import CodeBlock from "@/components/shared/mdx/code-block";
import Live from "@/components/shared/live";

export const metadata = project_metadata_collection["reclara"];

<SectionProvider>
<VideoDemo href={metadata.video_demo_url} />
  <h1 className="text-5xl font-bold mt-8">Reclara</h1>

YouTube video summarization system with automatic transcription and AI-powered summaries.

For installation and setup instructions, refer to the [README](https://github.com/nabilfaturr/reclara) on my github.

## Project Structure

- `apps/web` - Next.js frontend
- `apps/mq` - Message queue workers (BullMQ)
- `packages/db` - Database schemas & queries (Drizzle)
- `packages/redis` - Redis connection & queue setup
- `packages/env` - Environment configuration
- `packages/constants` - Shared constants

## Technical Architecture

### Database Schema

The core of Reclara's functionality revolves around the Summary table:

| Field | Type | Description |
| --- | --- | --- |
| id | UUID | Unique identifier (derived from YouTube video ID) |
| userId | UUID | Reference to the user who created the summary |
| transcript | text | Cleaned transcript extracted from the video |
| summarize | text | AI-generated summary result |
| model | enum | Type of LLM model used ("gpt-oss-120b" \| "llama-4-maverick" \| "Qwen3 Reranker 8B") |
| state | enum | Job state tracking ("pending" \| "start_transcript" \| "success_transcript" \| "start_summarizing" \| "finished" \| "error") |
| createdAt | timestamp | Record creation time |
| updatedAt | timestamp | Last update time |
| videoId | string(11) | YouTube video identifier |

### Workflow Overview

The Reclara system follows a distributed job queue architecture:

1. **User Submission** - User sends a YouTube video URL to the server
2. **Job Creation** - Server creates a record in the database with state "pending" and sends a job to the transcript worker
3. **Transcription** - Transcriber worker processes the video using yt-dlp to extract and clean the transcript
4. **Summarization** - Summarizer worker generates an AI-powered summary using the cleaned transcript
5. **Polling** - Client periodically polls the server to fetch results when state becomes "finished"

### Transcript Processing

The transcript extraction includes sophisticated fallback mechanisms:

- **Primary Extraction**: Uses `yt-dlp` to fetch YouTube video transcripts
- **Exponential Backoff Retry**: On failure, retries after 2s, 4s, and 8s to respect YouTube rate limits
- **Language Fallback**: Attempts English first, then Indonesian if not available
- **Cleaning**: Strips VTT metadata (timestamps, positioning) to extract only the text content

**Example Raw VTT Format:**
```
WEBVTT
Kind: captions
Language: en

00:00:14.310 --> 00:00:14.320 align:start position:0%
Kompas tonight on Kompas TV Independant.
```

**After Cleaning:**
```
Kompas tonight on Kompas TV Independant. Trustworthy, Brother. The first information...
```

### AI-Powered Summarization

The summarizer worker uses the Fireworks API with structured output:

1. **Prompt Engineering**: Generates a detailed prompt with specific instructions for JSON output and Markdown formatting
2. **Model Inference**: Sends the cleaned transcript to the LLM (GPT-OSS-120B, Llama 4, or Qwen3) via Fireworks API
3. **JSON Schema Validation**: Enforces JSON schema to ensure consistent output format
4. **Result Storage**: Saves the generated summary and updates the database state to "finished"

**Generated Summary Structure:**
```markdown
# Video Summary
[Opening paragraphs explaining main content]

## Main Points
- [Important point 1]
- [Important point 2]
- [Important point 3]

## Conclusion
[Closing paragraph with core message]
```

### Job Queue Architecture

Reclara uses a producer-consumer pattern with BullMQ and Redis:

- **Producer**: Creates jobs when users submit videos
- **Transcript Worker**: Processes transcript extraction jobs
- **Summarizer Worker**: Processes summarization jobs
- **Redis**: Acts as the message broker for reliable job distribution
- **State Management**: Each job progresses through defined states, enabling client-side polling

### Tools & Libraries

**Frontend:**
- Next.js - Full-stack React framework
- TypeScript - Static type checking
- Better-auth - Authentication system

**Backend:**
- Bun - JavaScript/TypeScript runtime
- Drizzle ORM - Type-safe database queries
- Turso + SQLite - Edge database
- Redis - In-memory task queue
- BullMQ - Redis-based job queue library
- yt-dlp - YouTube transcript extraction
- Fireworks AI - LLM inference platform with GPT-OSS-120B, Llama 4, and Qwen3 models

**Infrastructure:**
- Docker & Docker Compose - Local development containerization
- GCP Compute Engine - Backend deployment
- Vercel - Next.js frontend hosting
- GitHub Actions - CI/CD automation


</SectionProvider>
